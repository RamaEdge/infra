apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: harbor
  namespace: flux-system
spec:
  interval: 5m
  targetNamespace: harbor
  install:
    createNamespace: false
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  chart:
    spec:
      chart: harbor
      version: 1.18.1
      sourceRef:
        kind: HelmRepository
        name: harbor
        namespace: flux-system
  values:
    externalURL: https://harbor.theedgeworks.ai
    imagePullPolicy: IfNotPresent
    
    # Harbor Core Configuration
    # Using octohelm/harbor images from GHCR which support ARM64
    core:
      image:
        repository: ghcr.io/octohelm/harbor/harbor-core
        tag: v2.14.0
      # Note: OIDC configuration must be done via Harbor UI or API after deployment
      # Harbor stores OIDC settings in its database, not from environment variables
      # 
      # To configure Google Workspace OIDC:
      # 1. Log into Harbor as admin
      # 2. Go to Administration > Configuration > Authentication
      # 3. Set Auth Mode to "OIDC"
      # 4. Configure:
      #    - OIDC Provider Name: Google Workspace
      #    - OIDC Endpoint: https://accounts.google.com
      #    - OIDC Client ID: (from Google Cloud Console)
      #    - OIDC Client Secret: (from Google Cloud Console)
      #    - OIDC Scope: openid,profile,email
      #    - Verify Certificate: checked
      #    - Automatic onboarding: checked
      #    - Extra Redirect Parameters: {"hd":"theedgeworks.ai"}
      #
      # Alternatively, use the harbor-oidc-config Job (see harbor-oidc-config.yaml)
    portal:
      image:
        repository: ghcr.io/octohelm/harbor/harbor-portal
        tag: v2.14.0
    jobservice:
      image:
        repository: ghcr.io/octohelm/harbor/harbor-jobservice
        tag: v2.14.0
      # Ensure proper security context for storage access
      securityContext:
        runAsUser: 10000
        runAsGroup: 10000
        fsGroup: 10000
        fsGroupChangePolicy: OnRootMismatch
    registry:
      registry:
        image:
          repository: ghcr.io/octohelm/harbor/registry-photon
          tag: v2.14.0
        # Note: Command override not supported by Harbor Helm chart
        # Using Kustomize patch to set command: ["registry", "serve", "/etc/registry/config.yml"]
        # Ensure proper security context for storage access
        securityContext:
          runAsUser: 10000
          runAsGroup: 10000
          fsGroup: 10000
          fsGroupChangePolicy: OnRootMismatch
        # Override registry config to use /var/lib/registry as storage path
        # This matches the default registry image volume path
      controller:
        image:
          repository: ghcr.io/octohelm/harbor/harbor-registryctl
          tag: v2.14.0
    nginx:
      image:
        repository: ghcr.io/octohelm/harbor/nginx-photon
        tag: v2.14.0

    # Internal PostgreSQL configuration (harbor-db)
    # Using octohelm/harbor image for ARM64 support
    database:
      type: internal
      internal:
        image:
          repository: ghcr.io/octohelm/harbor/harbor-db
          tag: v2.14.0
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m

    # External Redis configuration
    # Using standalone Redis deployment (redis.yaml) for ARM64 compatibility
    redis:
      type: external
      external:
        addr: redis-service.harbor.svc.cluster.local:6379

    # Persistence configuration
    persistence:
      enabled: true
      persistentVolumeClaim:
        registry:
          size: 200Gi
          accessMode: ReadWriteOnce
          storageClass: longhorn
          # Mount path set to /var/lib/registry to match registry image default volume
          # This resolves permission issues when registry tries to write to /var/lib/registry/docker
          # Registry runs as UID 10000, fsGroup in pod securityContext handles permissions
        jobservice:
          size: 1Gi
          accessMode: ReadWriteOnce
          storageClass: longhorn
          # JobService runs as UID 10000, fsGroup in pod securityContext handles permissions
        trivy:
          size: 5Gi
          accessMode: ReadWriteOnce
          storageClass: longhorn
        database:
          size: 1Gi
          accessMode: ReadWriteOnce
          storageClass: longhorn
      imageChartStorage:
        type: filesystem
        filesystem:
          rootdirectory: /storage
          # Trivy runs as root (UID 0) by default, but fsGroup ensures proper permissions

    # TLS configuration
    expose:
      type: ingress
      tls:
        enabled: true
        certSource: secret
        secret:
          secretName: harbor-tls
      ingress:
        hosts:
          core: harbor.theedgeworks.ai
        className: traefik
        annotations:
          traefik.ingress.kubernetes.io/router.tls: "true"
          traefik.ingress.kubernetes.io/router.entrypoints: websecure
          traefik.ingress.kubernetes.io/router.middlewares: harbor-timeouts@kubernetescrd
    # Google Workspace OIDC Configuration
    # Note: Harbor Helm chart doesn't support OIDC configuration directly
    # OIDC configuration is added to the core section above via environment variables
    # Additional OIDC setup can be done via the harbor-oidc-init.yaml job

    # Trivy vulnerability scanner configuration
    # Using octohelm/harbor/trivy-adapter-photon from GHCR which supports ARM64
    trivy:
      enabled: true
      image:
        repository: ghcr.io/octohelm/harbor/trivy-adapter-photon
        tag: v2.14.0
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1Gi
      # Configure Trivy to scan for vulnerabilities
      vulnType: "os,library"
      severity: "UNKNOWN,LOW,MEDIUM,HIGH,CRITICAL"
      ignoreUnfixed: false
      securityCheck: "vuln"
      timeout: 5m0s
      # Use mirror repositories for better reliability
      dbRepository:
        - "mirror.gcr.io/aquasec/trivy-db"
        - "ghcr.io/aquasecurity/trivy-db"
      javaDBRepository:
        - "mirror.gcr.io/aquasec/trivy-java-db"
        - "ghcr.io/aquasecurity/trivy-java-db"

    # Disable components we don't need
    chartmuseum:
      enabled: false
    notary:
      enabled: false

    # Cosign Configuration
    # Harbor 2.13.0 supports Cosign for container image signing and verification
    # Cosign is enabled by default and configured at the project level
    # 
    # To enable Cosign for a project:
    # 1. Log in to Harbor web interface
    # 2. Navigate to your project
    # 3. Go to Configuration > Deployment Security
    # 4. Enable "Cosign" option
    #
    # To sign images with Cosign:
    # 1. Install Cosign CLI: https://github.com/sigstore/cosign
    # 2. Generate key pair: cosign generate-key-pair
    # 3. Sign image: cosign sign --key cosign.key harbor.theedgeworks.ai/project/image:tag
    # 4. Verify signature: cosign verify --key cosign.pub harbor.theedgeworks.ai/project/image:tag
    #
    # Note: Cosign signatures are stored as OCI artifacts alongside the main image
